{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gobblet Gobblers 환경 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        # end_check 함수를 간단하게 해줄 게임 판\n",
    "        self.board_v = np.zeros(9)\n",
    "        # 밑에 있는 보드는 0으로 초기화된 27개의 배열로 준비\n",
    "        self.board_r = np.zeros(27)\n",
    "\n",
    "        # 게임 종료: done = True\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.winner = 0\n",
    "        self.print = True\n",
    "\n",
    "        self.p1_small_piece = 2\n",
    "        self.p1_medium_piece = 2\n",
    "        self.p1_large_piece = 2\n",
    "\n",
    "        self.p2_small_piece = 2\n",
    "        self.p2_medium_piece = 2\n",
    "        self.p2_large_piece = 2\n",
    "\n",
    "    def move(self, player1, player2, player):\n",
    "        # 각 플레이어가 선택한 행동을 표시하고 게임 상태(진행 또는 종료)를 판단\n",
    "        # p1 = 1. p2 = -1로 정의\n",
    "        # 긱 플레이어는 행동을 선택하는 select_action 메서드를 가짐\n",
    "\n",
    "        if player == 1:\n",
    "            pos = player1.select_action(self, player)\n",
    "\n",
    "        else:\n",
    "            pos = player2.select_action(self, player)\n",
    "\n",
    "        # 보드에 플레이어의 선택을 표시(만약 새로운 말을 놓는 거라면)\n",
    "        if isinstance(pos, int):  # 숫자라면\n",
    "            self.board_r[pos] = player\n",
    "        else:  # 문자라면 -> 움직이는 액션이다\n",
    "            pos = pos.split('to')  # pos[0]가 지울 장소, pos[1]이 생길 장소\n",
    "\n",
    "            # 원래 있던 자리에 있는 말을 지우고, (real 에서만 지우면 된다) 옮길 자리에 추가한다(마찬가지로 real 에서만 추가하면 된다.)\n",
    "            self.board_r[int(pos[0])] = 0\n",
    "            self.board_r[int(pos[1])] = player\n",
    "\n",
    "        if self.print:\n",
    "            self.print_board()\n",
    "\n",
    "        # 보이는 보드로의 복사(end_check 함수를 간단히 만들기 위함)\n",
    "        self.copy_real_to_vision()\n",
    "\n",
    "        # 게임이 종료 상태인지 아닌지를 판단\n",
    "        # print(player)\n",
    "        self.end_check(player)\n",
    "        return self.reward, self.done\n",
    "\n",
    "    # 현재 보드 상태에서 가능한 행동(들 수 있는 장소)을 탐색하고 리스트로 반환\n",
    "    def get_action(self, player):\n",
    "        observation = []\n",
    "\n",
    "        if player == 1:\n",
    "            if self.p1_large_piece != 0:\n",
    "                for i in range(18, 27):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "            if self.p1_medium_piece != 0:\n",
    "                for i in range(9, 18):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "            if self.p1_small_piece != 0:\n",
    "                for i in range(9):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "        else:  # player == 2\n",
    "            if self.p2_large_piece != 0:\n",
    "                for i in range(18, 27):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "            if self.p2_medium_piece != 0:\n",
    "                for i in range(9, 18):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "            if self.p2_small_piece != 0:\n",
    "                for i in range(9):\n",
    "                    if self.board_r[i] == 0:\n",
    "                        observation.append(i)\n",
    "\n",
    "        #  중간말이 놓인 위치에는 작은 말을 놓을 수 없다.(제거 작업)\n",
    "        for i in range(9, 18):\n",
    "            if self.board_r[i] != 0 and self.board_r[i - 9] == 0:\n",
    "                if i-9 in observation:\n",
    "                    observation.remove(i - 9)\n",
    "\n",
    "        for i in range(18, 27):\n",
    "            # 큰 말이 놓인 위치에는 중간말과 작은 말을 놓을 수 없다.\n",
    "            if self.board_r[i] != 0 and self.board_r[i - 9] == 0:\n",
    "                if i - 9 in observation:\n",
    "                    observation.remove(i - 9)\n",
    "            if self.board_r[i] != 0 and self.board_r[i - 18] == 0:\n",
    "                if i - 18 in observation:\n",
    "                    observation.remove(i - 18)\n",
    "\n",
    "        observation.sort()  # 정렬\n",
    "        \n",
    "        # 이동 가능한 경우의 수 추가\n",
    "        for i in range(9):\n",
    "            if self.board_r[i] == player and self.board_r[i+9] == 0 and self.board_r[i+18] == 0:\n",
    "                for j in range(9):\n",
    "                    if self.board_r[j] == 0 and self.board_r[j+9] == 0 and self.board_r[j+18] == 0:\n",
    "                        observation.append(str(i) + 'to' + str(j))\n",
    "\n",
    "        for i in range(9, 18):\n",
    "            if self.board_r[i] == player and self.board_r[i+9] == 0:\n",
    "                for j in range(9,18):\n",
    "                    if self.board_r[j] == 0 and self.board_r[j+9] == 0:\n",
    "                        observation.append(str(i)+'to'+str(j))\n",
    "\n",
    "        for i in range(18, 27):\n",
    "            if self.board_r[i] == player:\n",
    "                # 옮길 수 있는 위치 탐색\n",
    "                for j in range(18, 27):\n",
    "                    # 빈 공간이면\n",
    "                    if self.board_r[j] == 0:\n",
    "                        observation.append(str(i)+'to'+str(j))\n",
    "\n",
    "        return observation\n",
    "\n",
    "    # 게임이 종료(승패 또는 비김)됐는지 판단\n",
    "    def end_check(self, player):\n",
    "        # 0 1 2\n",
    "        # 3 4 5\n",
    "        # 6 7 8\n",
    "        # 승패 조건은 가로, 세로, 대각선이 -1이나 1로 동일할 때\n",
    "        end_condition = ((0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6))  # 승패 조건 생성\n",
    "        \n",
    "        # 이긴사람의 수 카운트 -> 두명 다 라인을 완성할 경우 비기므로\n",
    "        p1_cnt = 0\n",
    "        p2_cnt = 0\n",
    "        # 승리 판별\n",
    "        for line in end_condition:\n",
    "            if self.board_v[line[0]] == self.board_v[line[1]] and \\\n",
    "                self.board_v[line[1]] == self.board_v[line[2]] and \\\n",
    "                    self.board_v[line[0]] == 1:  # 플레이어1 이 이겼다면\n",
    "                # 종료됐다면 누가 이겼는지 표시\n",
    "                self.done = True\n",
    "                self.reward = 1\n",
    "                p1_cnt += 1\n",
    "            if self.board_v[line[0]] == self.board_v[line[1]] and \\\n",
    "                self.board_v[line[1]] == self.board_v[line[2]] and \\\n",
    "                    self.board_v[line[0]] == -1:  # 플레이어2 이 이겼다면\n",
    "                # 종료됐다면 누가 이겼는지 표시\n",
    "                self.done = True\n",
    "                self.reward = -1\n",
    "                p2_cnt += 1\n",
    "\n",
    "        # 비긴 상태. 양쪽 모두 승리 조건을 동시에 만족하는 경우.\n",
    "        if p1_cnt >= 1 and p2_cnt >= 1:\n",
    "            self.done = True\n",
    "            self.reward = 0\n",
    "        return\n",
    "\n",
    "    # 현재 보드의 상태를 표시: p1 = 0'', p2 = X''\n",
    "    def print_board(self):\n",
    "        print(\"+----+----+----+\")\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board_r[3 * i + j + 18] == 1:\n",
    "                    print(\"| OL\", end=\" \")\n",
    "                elif self.board_r[3 * i + j + 18] == -1:\n",
    "                    print(\"| XL\", end=\" \")\n",
    "                elif self.board_r[3 * i + j + 9] == 1:\n",
    "                    print(\"| Om\", end=\" \")\n",
    "                elif self.board_r[3 * i + j + 9] == -1:\n",
    "                    print(\"| Xm\", end=\" \")\n",
    "                elif self.board_r[3 * i + j] == 1:\n",
    "                    print(\"| Os\", end=\" \")\n",
    "                elif self.board_r[3 * i + j] == -1:\n",
    "                    print(\"| Xs\", end=\" \")\n",
    "                else:\n",
    "                    print(\"|   \", end=\" \")\n",
    "            print(\"|\")\n",
    "            print(\"+----+----+----+\")\n",
    "        return\n",
    "    \n",
    "    # 맨 위의 게임 말만 표시하는 보드로 나타내기 end_check함수를 간단하게 작성하기 위함\n",
    "    def copy_real_to_vision(self):\n",
    "        self.board_v = np.zeros(9)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board_r[3 * i + j + 18] == 1:\n",
    "                    self.board_v[3 * i + j] = 1\n",
    "                elif self.board_r[3 * i + j + 18] == -1:\n",
    "                    self.board_v[3 * i + j] = -1\n",
    "                elif self.board_r[3 * i + j + 9] == 1:\n",
    "                    self.board_v[3 * i + j] = 1\n",
    "                elif self.board_r[3 * i + j + 9] == -1:\n",
    "                    self.board_v[3 * i + j] = -1\n",
    "                elif self.board_r[3 * i + j] == 1:\n",
    "                    self.board_v[3 * i + j] = 1\n",
    "                elif self.board_r[3 * i + j] == -1:\n",
    "                    self.board_v[3 * i + j] = -1\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인간 플레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human_player:\n",
    "    def __init__(self):\n",
    "        self.name = \"Human player\"\n",
    "        self.flag = 0\n",
    "\n",
    "    def select_action(self, environment, player):\n",
    "        while True:\n",
    "            # 가능한 행동을 조사한 후 표시\n",
    "            available_action = environment.get_action(player)\n",
    "\n",
    "            print(\"possible actions = {}\".format(available_action))\n",
    "\n",
    "            # 상태 번호 표시\n",
    "            print(\"+----+----+----+\")\n",
    "            print(\"+  0 +  1 +  2 +\")\n",
    "            print(\"+----+----+----+\")\n",
    "            print(\"+  3 +  4 +  5 +\")\n",
    "            print(\"+----+----+----+\")\n",
    "            print(\"+  6 +  7 +  8 +\")\n",
    "            print(\"+----+----+----+\")\n",
    "\n",
    "            # 키보드로 가능한 행동을 입력받음\n",
    "            first_input = input(\"0-26 to move, n to place a new piece?\")\n",
    "            action = -1  # 선택한 행동이 선택할 수 없는 행동일 경우를 대비\n",
    "            size = -1  # 선택한 행동이 size를 상관 안하면\n",
    "            # 새로운 말을 놓겠다면\n",
    "            if first_input == 'n':\n",
    "                # 만약 새롭게 놓을 말이 없으면\n",
    "                if player == 1 and environment.p1_small_piece + environment.p1_medium_piece + environment.p1_large_piece == 0:\n",
    "                    # 놓을 수 없다!\n",
    "                    self.flag = 1\n",
    "                elif player == -1 and environment.p2_small_piece + environment.p2_medium_piece + environment.p2_large_piece == 0:\n",
    "                    # 놓을 수 없다!\n",
    "                    self.flag = 1\n",
    "\n",
    "                else:\n",
    "                    # 놓을 수 있는 말이 있으면 size를 입력 받는다\n",
    "                    size = int(input(\"What size piece would you like to use? (0-2)\"))\n",
    "                    # 만약 그 사이즈에 해당하는 말이 없으면 놓을 수 없다.\n",
    "                    if player == 1:\n",
    "                        if size == 0 and environment.p1_small_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        elif size == 1 and environment.p1_medium_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        elif size == 2 and environment.p1_large_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        else:\n",
    "                            # 위치 입력받음\n",
    "                            location = int(input(\"What square would you like to move to? (0-8)\"))\n",
    "                            action = location + size * 9\n",
    "\n",
    "                    else:  # player == 2:\n",
    "                        if size == 0 and environment.p2_small_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        elif size == 1 and environment.p2_medium_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        elif size == 2 and environment.p2_large_piece == 0:\n",
    "                            self.flag = 1\n",
    "                        else:\n",
    "                            # 위치 입력받음\n",
    "                            location = int(input(\"What square would you like to move to? (0-8)\"))\n",
    "                            action = location + size * 9\n",
    "\n",
    "            elif first_input.isdigit():  # 옮기는 행동을 입력받음\n",
    "                first_input = int(first_input)  # 0-26 인 숫자\n",
    "                if 0 <= first_input <= 26:\n",
    "                    if environment.board_r[first_input] != player:  # 그 위치에 자기 말이 없다면 wrong action\n",
    "                        self.flag = 1\n",
    "                    else:\n",
    "                        location = int(input(\"What square would you like to move to? (0-26)\"))  # 비어있는 곳으로 이동 가능하다.\n",
    "                        action = str(first_input) + 'to' + str(location)\n",
    "                else:\n",
    "                    self.flag = 1\n",
    "\n",
    "            else:  # 잘못된 입력\n",
    "                self.flag = 1\n",
    "\n",
    "            # 입력받은 행동이 가능한 행동이면 반복문을 탈출\n",
    "            if action in available_action and self.flag == 0:\n",
    "                if player == 1:\n",
    "                    if size == 0:\n",
    "                        environment.p1_small_piece -= 1\n",
    "                    elif size == 1:\n",
    "                        environment.p1_medium_piece -= 1\n",
    "                    elif size == 2:\n",
    "                        environment.p1_large_piece -= 1\n",
    "\n",
    "                else:  # player == 2\n",
    "                    if size == 0:\n",
    "                        environment.p2_small_piece -= 1\n",
    "                    elif size == 1:\n",
    "                        environment.p2_medium_piece -= 1\n",
    "                    elif size == 2:\n",
    "                        environment.p2_large_piece -= 1\n",
    "                # 옮기느라 사이즈가 없으면 그냥 return\n",
    "                return action\n",
    "            # 아니면 행동 입력을 반복\n",
    "            else:\n",
    "                print(\"You selected wrong action\")\n",
    "                environment.print_board()\n",
    "                self.flag = 0\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 플레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_player:\n",
    "    def __init__(self):\n",
    "        self.name = \"Random player\"\n",
    "\n",
    "    def select_action(self, environment, player):\n",
    "        # 가능한 행동 조사\n",
    "        available_action = environment.get_action(player)\n",
    "        # 가능한 행동 중 하나를 무작위로 선택\n",
    "        action = np.random.randint(len(available_action))\n",
    "\n",
    "        # 선택한 행동이 새로 말을 놓는 행동이라면 값을 빼주어야함.\n",
    "        if isinstance(available_action[action], int):  # 숫자라면\n",
    "            if player == 1:\n",
    "                if 0 <= available_action[action] <= 8:\n",
    "                    environment.p1_small_piece -= 1\n",
    "                elif 9 <= available_action[action] <= 17:\n",
    "                    environment.p1_medium_piece -= 1\n",
    "                else:  # 18 <= action <= 26\n",
    "                    environment.p1_large_piece -= 1\n",
    "            else:  # player == 2:\n",
    "                if 0 <= available_action[action] <= 8:\n",
    "                    environment.p2_small_piece -= 1\n",
    "                elif 9 <= available_action[action] <= 17:\n",
    "                    environment.p2_medium_piece -= 1\n",
    "                else:  # 18 <= action <= 26\n",
    "                    environment.p2_large_piece -= 1\n",
    "\n",
    "        return available_action[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 몬테카를로 플레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monte_Carlo_player:\n",
    "    def __init__(self):\n",
    "        self.name = \"MC player\"\n",
    "        self.num_playout = 300\n",
    "\n",
    "    def select_action(self, environment, player):\n",
    "        # 가능한 행동 조사\n",
    "        available_action = environment.get_action(player)\n",
    "        # 상태가치를 저장할 배열 V\n",
    "        V = np.zeros(len(available_action))\n",
    "\n",
    "        # 가능한 행동들을 돌면서 V[i]+=1을 해줌\n",
    "        for i in range(len(available_action)):\n",
    "            # 플레이 아웃을 1000번 반복\n",
    "            for j in range(self.num_playout):\n",
    "                # 지금 상태를 복사해서 플레이 아웃에 사용\n",
    "                temp_env = copy.deepcopy(environment)\n",
    "                # play out 의 결과는 승리플레이어의 값으로 반환\n",
    "                # p1이 이기면 1, p2가 이기면 -1\n",
    "\n",
    "                # i번째 행동이 새로 말을 놓는 행동이라면 값을 빼주어야함.\n",
    "                if isinstance(available_action[i], int):  # 숫자라면\n",
    "                    if 0 <= available_action[i] <= 8:\n",
    "                        if player == 1:\n",
    "                            temp_env.p1_small_piece -= 1\n",
    "                        else:\n",
    "                            temp_env.p2_small_piece -= 1\n",
    "                    elif 9 <= available_action[i] <= 17:\n",
    "                        if player == 1:\n",
    "                            temp_env.p1_medium_piece -= 1\n",
    "                        else:\n",
    "                            temp_env.p2_medium_piece -= 1\n",
    "                    else:  # 18 <= action <= 26\n",
    "                        if player == 1:\n",
    "                            temp_env.p1_large_piece -= 1\n",
    "                        else:\n",
    "                            temp_env.p2_large_piece -= 1\n",
    "\n",
    "                self.playout(temp_env, available_action[i], player)\n",
    "                if player == temp_env.reward:\n",
    "                    V[i] += 1\n",
    "\n",
    "        # 가장 승률이 높은 행동을 저장\n",
    "        action = np.argmax(V)\n",
    "\n",
    "        # 선택한 행동이 새로 말을 놓는 행동이라면 값을 빼주어야함.\n",
    "        if isinstance(available_action[action], int):  # 숫자라면\n",
    "            if 0 <= available_action[action] <= 8:\n",
    "                if player == 1:\n",
    "                    env.p1_small_piece -= 1\n",
    "                else:\n",
    "                    env.p2_small_piece -= 1\n",
    "            elif 9 <= available_action[action] <= 17:\n",
    "                if player == 1:\n",
    "                    env.p1_medium_piece -= 1\n",
    "                else:\n",
    "                    env.p2_medium_piece -= 1\n",
    "            else:  # 18 <= action <= 26\n",
    "                if player == 1:\n",
    "                    env.p1_large_piece -= 1\n",
    "                else:\n",
    "                    env.p2_large_piece -= 1\n",
    "\n",
    "        return available_action[action]\n",
    "\n",
    "    # 플레이 아웃 재귀함수\n",
    "    # 게임이 종료상태 (승 또는 패 또는 비김)가 될때까지 행동을 임의로 선택하는 것을 반복\n",
    "    # 플레이어는 계속 바뀌기 때문에 (-)를 곱해서 -1, 1, -1 이 되게 함.\n",
    "\n",
    "    def playout(self, temp_env, action, player):\n",
    "        # 보드에 플레이어의 선택을 표시(만약 새로운 말을 놓는 거라면)\n",
    "        if isinstance(action, int):  # 숫자라면\n",
    "            temp_env.board_r[action] = player\n",
    "        else:  # 문자라면 -> 움직이는 액션이다\n",
    "            action = action.split('to')  # pos[0]가 지울 장소, pos[1]이 생길 장소\n",
    "\n",
    "            # 원래 있던 자리에 있는 말을 지우고, (real 보드에만 지우면 된다) 옮길 자리에 추가한다(마찬가지로 real 보드에만 추가하면 된다.)\n",
    "            temp_env.board_r[int(action[0])] = 0\n",
    "            temp_env.board_r[int(action[1])] = player\n",
    "\n",
    "        temp_env.copy_real_to_vision()\n",
    "        temp_env.end_check(player)\n",
    "        # 게임 종료 체크\n",
    "        if temp_env.done:\n",
    "            # print(\"done\")\n",
    "            return\n",
    "        else:\n",
    "            # 플레이어 교체\n",
    "            player = -player\n",
    "            # 가능한 행동 조사\n",
    "            available_action = temp_env.get_action(player)\n",
    "\n",
    "            # 무작위로 행동을 선택\n",
    "            action = np.random.randint(len(available_action))\n",
    "\n",
    "            # 선택한 행동이 새로 말을 놓는 행동이라면 값을 빼주어야함.\n",
    "            if isinstance(available_action[action], int):  # 숫자라면\n",
    "                if 0 <= available_action[action] <= 8:\n",
    "                    if player == 1:\n",
    "                        temp_env.p1_small_piece -= 1\n",
    "                    else:\n",
    "                        temp_env.p2_small_piece -= 1\n",
    "                elif 9 <= available_action[action] <= 17:\n",
    "                    if player == 1:\n",
    "                        temp_env.p1_medium_piece -= 1\n",
    "                    else:\n",
    "                        temp_env.p2_medium_piece -= 1\n",
    "                else:  # 18 <= action <= 26\n",
    "                    if player == 1:\n",
    "                        temp_env.p1_large_piece -= 1\n",
    "                    else:\n",
    "                        temp_env.p2_large_piece -= 1\n",
    "\n",
    "            self.playout(temp_env, available_action[action], player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning 플레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_learning_player:\n",
    "    def __init__(self):\n",
    "        self.name = \"Q_player\"\n",
    "        # Q-table을 딕셔너리로 정의\n",
    "        self.qtable = {}\n",
    "        # e-greedy 계수 정의\n",
    "        self.epsilon = 1\n",
    "        # 학습률 정의\n",
    "        self.learning_rate = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.print = False\n",
    "\n",
    "    # policy 에 따라 상태에 맞는 행동을 선택\n",
    "    def select_action(self, environment, c_player):\n",
    "        # policy 에 따라 행동을 선택\n",
    "        action = self.policy(environment, c_player)\n",
    "        return action\n",
    "\n",
    "    def policy(self, environment, c_player):\n",
    "        # 행동 가능한 상태를 저장\n",
    "        available_action = environment.get_action(c_player)\n",
    "        # 행동 가능한 상태의 Q-value를 저장\n",
    "        qvalues = np.zeros(len(available_action))\n",
    "\n",
    "        # 행동 가능한 상태의 Q-value를 조사\n",
    "        for i, act in enumerate(available_action):\n",
    "            key = (tuple(environment.board_r), act)\n",
    "\n",
    "            # 현재 상태를 경험한 적이 없다면(딕셔너리에 없다면) 딕셔너리에 추가(Q-value = 0)\n",
    "            if self.qtable.get(key) == None:\n",
    "                self.qtable[key] = 0\n",
    "            # 행동 가능한 상태의 Q-value 저장\n",
    "            qvalues[i] = self.qtable.get(key)\n",
    "\n",
    "        # e-greedy\n",
    "        # 가능한 행동들 중에서 Q-value 가 가장 큰 행동을 저장\n",
    "        greedy_action = np.argmax(qvalues)\n",
    "\n",
    "        # max Q-value와 같은 값이 여러개 있는지 확인한 후 double_check에 상태를 저장\n",
    "        double_check = (np.where(qvalues == np.max(qvalues), 1, 0))\n",
    "\n",
    "        # 여러개 있다면 중복된 상태중에서 다시 무작위로 선택\n",
    "        if np.sum(double_check) > 1:\n",
    "            double_check = double_check / np.sum(double_check)\n",
    "            greedy_action = np.random.choice(range(0, len(double_check)), p=double_check)\n",
    "            \n",
    "        # e-greedy 로 행동들의 선택 확률을 계산\n",
    "        pr = np.zeros(len(available_action))\n",
    "\n",
    "        for i in range(len(available_action)):\n",
    "            if i == greedy_action:\n",
    "                pr[i] = 1 - self.epsilon + self.epsilon / len(available_action)\n",
    "                if pr[i] < 0:\n",
    "                    print(\"{} : - pr\".format(np.round(pr[i], 2)))\n",
    "            else:\n",
    "                pr[i] = self.epsilon / len(available_action)\n",
    "                if pr[i] < 0:\n",
    "                    print(\"{} : - pr\".format(np.round(pr[i], 2)))\n",
    "\n",
    "        action = np.random.choice(range(0, len(available_action)), p=pr)\n",
    "\n",
    "        # 선택한 행동이 새로 말을 놓는 행동이라면 값을 빼주어야함.\n",
    "        if isinstance(available_action[action], int):  # 숫자라면\n",
    "            if 0 <= available_action[action] <= 8:\n",
    "                if c_player == 1:\n",
    "                    environment.p1_small_piece -= 1\n",
    "                else:\n",
    "                    environment.p2_small_piece -= 1\n",
    "            elif 9 <= available_action[action] <= 17:\n",
    "                if c_player == 1:\n",
    "                    environment.p1_medium_piece -= 1\n",
    "                else:\n",
    "                    environment.p2_medium_piece -= 1\n",
    "            else:  # 18 <= action <= 26\n",
    "                if c_player == 1:\n",
    "                    environment.p1_large_piece -= 1\n",
    "                else:\n",
    "                    environment.p2_large_piece -= 1\n",
    "\n",
    "        action = available_action[action]\n",
    "        return action\n",
    "    \n",
    "    def learn_qtable(self, board_backup, action_backup, environment, c_reward, c_player):\n",
    "        # 현재 상태와 행동을 키로 저장\n",
    "        key = (board_backup, action_backup)\n",
    "\n",
    "        # Q-table 학습\n",
    "        if environment.done:\n",
    "            # 게임이 끝났을 경우 학습\n",
    "            self.qtable[key] += self.learning_rate * (c_reward - self.qtable[key])\n",
    "        else:\n",
    "            # 게임이 진행중일 경우 학습\n",
    "            # 다음 상태의 max Q 값 계산\n",
    "            available_action = environment.get_action(c_player)\n",
    "\n",
    "            qvalues = np.zeros(len(available_action))\n",
    "\n",
    "            for i, act in enumerate(available_action):\n",
    "                next_key = (tuple(env.board_r), act)\n",
    "\n",
    "                # 다음 상태를 경험한 적이 없다면(딕셔너리에 없다면) 딕셔너리에 추가(Q-value = 0)\n",
    "                if self.qtable.get(next_key) == None:\n",
    "                    self.qtable[next_key] = 0\n",
    "                qvalues[i] = self.qtable.get(next_key)\n",
    "\n",
    "            # maxQ 조사\n",
    "            maxQ = np.max(qvalues)\n",
    "\n",
    "            # 게임이 진행중일 때 학습\n",
    "            self.qtable[key] += self.learning_rate * (c_reward + self.gamma * maxQ - self.qtable[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning 플레이어 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100000/100000 [13:30<00:00, 123.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 = 56409 p2 = 42973 draw = 618\n",
      "end train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p1_Qplayer = Q_learning_player()\n",
    "p2_Qplayer = Q_learning_player()\n",
    "\n",
    "# 입실론은 0.5로 설장\n",
    "p1_Qplayer.epsilon = 0.5\n",
    "p2_Qplayer.epsilon = 0.5\n",
    "\n",
    "p1_score = 0\n",
    "p2_score = 0\n",
    "draw_score = 0\n",
    "max_learn =100000\n",
    "\n",
    "for j in tqdm(range(max_learn)):\n",
    "    np.random.seed(j)\n",
    "    env = Environment()\n",
    "    for i in range(10000):\n",
    "        # p1 행동 선택\n",
    "        player = 1\n",
    "        pos = p1_Qplayer.policy(env, player)\n",
    "        \n",
    "        # 현재 상태 s, 행동 a를 저장\n",
    "        p1_board_backup = tuple(env.board_r)\n",
    "        p1_action_backup = pos\n",
    "        \n",
    "        if isinstance(pos, int):  # 숫자라면\n",
    "            env.board_r[pos] = player\n",
    "        else:  # 문자라면 -> 움직이는 액션이다\n",
    "            pos = pos.split('to')  # pos[0]가 지울 장소, pos[1]이 생길 장소\n",
    "            env.board_r[int(pos[0])] = 0\n",
    "            env.board_r[int(pos[1])] = player\n",
    "        \n",
    "        env.copy_real_to_vision()\n",
    "        env.end_check(player)\n",
    "        \n",
    "        # 게임이 종료상태라면 각 플레이어의 Q-table을 학습\n",
    "        if env.done:\n",
    "            # 비겼으면 보수 0\n",
    "            if env.reward == 0:\n",
    "                p1_Qplayer.learn_qtable(p1_board_backup, p1_action_backup, env, 0, player)\n",
    "                p2_Qplayer.learn_qtable(p2_board_backup, p2_action_backup, env, 0, player)\n",
    "                draw_score += 1   \n",
    "                break\n",
    "            # p1이 이겼으므로 보상 +1\n",
    "            # p2이 졌으므로 보상 -1\n",
    "            else:\n",
    "                p1_Qplayer.learn_qtable(p1_board_backup, p1_action_backup, env, 1, player)\n",
    "                p2_Qplayer.learn_qtable(p2_board_backup, p2_action_backup, env, -1, player)\n",
    "                p1_score += 1\n",
    "                break\n",
    "\n",
    "        # 게임이 끝나지 않았다면 p2의 Q-table을 학습 (게임 시작직후에는 p2는 학습할 수 없음)\n",
    "        if i != 0:\n",
    "            p2_Qplayer.learn_qtable(p2_board_backup, p2_action_backup, env, -0.01, player)\n",
    "        \n",
    "        # p2 행동 선택\n",
    "        player = -1\n",
    "        pos = p2_Qplayer.policy(env, player)\n",
    "        \n",
    "        p2_board_backup = tuple(env.board_r)\n",
    "        p2_action_backup = pos\n",
    "        \n",
    "        if isinstance(pos, int):  # 숫자라면\n",
    "            env.board_r[pos] = player\n",
    "        else:  # 문자라면 -> 움직이는 액션이다\n",
    "            pos = pos.split('to')  # pos[0]가 지울 장소, pos[1]이 생길 장소\n",
    "\n",
    "            # 원래 있던 자리에 있는 말을 지우고, (real 보드에만 지우면 된다) 옮길 자리에 추가한다(마찬가지로 real 보드에만 추가하면 된다.)\n",
    "            env.board_r[int(pos[0])] = 0\n",
    "            env.board_r[int(pos[1])] = player\n",
    "        \n",
    "        env.copy_real_to_vision()\n",
    "        env.end_check(player)\n",
    "\n",
    "        if env.done:\n",
    "            # 비겼으면 보수 0\n",
    "            if env.reward == 0:\n",
    "                p1_Qplayer.learn_qtable(p1_board_backup, p1_action_backup, env, 0, player)\n",
    "                p2_Qplayer.learn_qtable(p2_board_backup, p2_action_backup, env, 0, player)\n",
    "                draw_score += 1\n",
    "                break\n",
    "            # p2이 이겼으므로 보상 +1\n",
    "            # p1이 졌으므로 보상 -1\n",
    "            else:\n",
    "                p1_Qplayer.learn_qtable(p1_board_backup, p1_action_backup, env, -1, player)\n",
    "                p2_Qplayer.learn_qtable(p2_board_backup, p2_action_backup, env, 1, player)\n",
    "                p2_score += 1\n",
    "                break\n",
    "\n",
    "        # 게임이 끝나지 않았다면 p1의 Q-table 학습\n",
    "        p1_Qplayer.learn_qtable(p1_board_backup, p1_action_backup, env, -0.01, player)\n",
    "        # # 1000 게임마다 게임 결과 표시\n",
    "#         if j % 1000 == 0:\n",
    "            # print(\"j = {} p1 = {} p2 = {} draw = {}\".format(j, p1_score, p2_score, draw_score))\n",
    "            \n",
    "print(\"p1 = {} p2 = {} draw = {}\".format(p1_score, p2_score, draw_score))\n",
    "print(\"end train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 player : Human player\n",
      "p2 player : Q_player\n",
      "possible actions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "+----+----+----+\n",
      "+  0 +  1 +  2 +\n",
      "+----+----+----+\n",
      "+  3 +  4 +  5 +\n",
      "+----+----+----+\n",
      "+  6 +  7 +  8 +\n",
      "+----+----+----+\n",
      "0-26 to move, n to place a new piece?n\n",
      "What size piece would you like to use? (0-2)2\n",
      "What square would you like to move to? (0-8)4\n",
      "+----+----+----+\n",
      "|    |    |    |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "|    |    |    |\n",
      "+----+----+----+\n",
      "+----+----+----+\n",
      "|    | XL |    |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "|    |    |    |\n",
      "+----+----+----+\n",
      "possible actions = [0, 2, 3, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, '22to18', '22to20', '22to21', '22to23', '22to24', '22to25', '22to26']\n",
      "+----+----+----+\n",
      "+  0 +  1 +  2 +\n",
      "+----+----+----+\n",
      "+  3 +  4 +  5 +\n",
      "+----+----+----+\n",
      "+  6 +  7 +  8 +\n",
      "+----+----+----+\n",
      "0-26 to move, n to place a new piece?n\n",
      "What size piece would you like to use? (0-2)2\n",
      "What square would you like to move to? (0-8)6\n",
      "+----+----+----+\n",
      "|    | XL |    |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "| OL |    |    |\n",
      "+----+----+----+\n",
      "+----+----+----+\n",
      "|    | XL |    |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "| OL | XL |    |\n",
      "+----+----+----+\n",
      "possible actions = [0, 2, 3, 5, 8, 9, 11, 12, 14, 17, '22to18', '22to20', '22to21', '22to23', '22to26', '24to18', '24to20', '24to21', '24to23', '24to26']\n",
      "+----+----+----+\n",
      "+  0 +  1 +  2 +\n",
      "+----+----+----+\n",
      "+  3 +  4 +  5 +\n",
      "+----+----+----+\n",
      "+  6 +  7 +  8 +\n",
      "+----+----+----+\n",
      "0-26 to move, n to place a new piece?n\n",
      "What size piece would you like to use? (0-2)1\n",
      "What square would you like to move to? (0-8)2\n",
      "+----+----+----+\n",
      "|    | XL | Om |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "| OL | XL |    |\n",
      "+----+----+----+\n",
      "winner is p1(Human player)\n",
      "final result\n",
      "+----+----+----+\n",
      "|    | XL | Om |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "| OL | XL |    |\n",
      "+----+----+----+\n",
      "final result\n",
      "+----+----+----+\n",
      "|    | XL | Om |\n",
      "+----+----+----+\n",
      "|    | OL |    |\n",
      "+----+----+----+\n",
      "| OL | XL |    |\n",
      "+----+----+----+\n",
      "More Game? (y/n)n\n",
      "p1(Human player) = 1 p2(Q_player) = 0 draw = 0\n"
     ]
    }
   ],
   "source": [
    "# 인간 vs 인간\n",
    "# p1 = Human_player()\n",
    "# p2 = Human_player()\n",
    "\n",
    "# 인간 vs 랜덤 플레이어\n",
    "# p1 = Human_player()\n",
    "# p2 = Random_player()\n",
    "\n",
    "# 인간 vs MCTS 플레이어\n",
    "# p1 = Human_player()\n",
    "# p2 = Monte_Carlo_player()\n",
    "\n",
    "# 인간 vs Q-learning Player\n",
    "p1 = Human_player()\n",
    "p2 = p2_Qplayer\n",
    "p2.epsilon = 0\n",
    "\n",
    "# 지정된 게임 수를 자동으로 두게 할 것인지 한 게임씩 두게 할 것인지 결정\n",
    "# auto = True: 지정된 판 수(games)를 자동으로 진행\n",
    "# auto = False: 한 게임씩 진행\n",
    "\n",
    "auto = False\n",
    "# auto = True\n",
    "\n",
    "# auto 모드의 게임 수\n",
    "games = 100\n",
    "print(\"p1 player : {}\".format(p1.name))\n",
    "print(\"p2 player : {}\".format(p2.name))\n",
    "\n",
    "# 각 플레이어의 승리 횟수를 저장\n",
    "p1_score = 0\n",
    "p2_score = 0\n",
    "draw_score = 0\n",
    "if auto:\n",
    "    \n",
    "    # 자동 모드 실행\n",
    "    for j in tqdm(range(games)):\n",
    "        np.random.seed(j)\n",
    "        env = Environment()\n",
    "        for i in range(10000):\n",
    "            \n",
    "            # p1과 p2가 번갈아 가면서 게임을 진행\n",
    "            # p1(1) -> p2(-1) -> p1(1) -> p2(-1) ...\n",
    "            reward, done = env.move(p1, p2, (-1)**i)\n",
    "            \n",
    "            # 게임 종료 체크\n",
    "            if done == True:\n",
    "                if reward == 1:\n",
    "                    print(\"j = {} winner is p1{}\".format(j, p1.name))\n",
    "                    p1_score += 1\n",
    "                elif reward == -1:\n",
    "                    print(\"j = {} winner is p2{}\".format(j, p2.name))\n",
    "                    p2_score += 1\n",
    "                else:\n",
    "                    print(\"j = {} draw\".format(j))\n",
    "                    draw_score += 1\n",
    "                break\n",
    "                \n",
    "else:\n",
    "    # 한 게임씩 진행하는 수동 모드\n",
    "    while True:\n",
    "        env = Environment()\n",
    "        env.print = True\n",
    "        for i in range(10000):\n",
    "            reward, done = env.move(p1,p2,(-1)**i)\n",
    "            \n",
    "            # 게임 종료 체크\n",
    "            if done == True:\n",
    "                if reward == 1:\n",
    "                    print(\"winner is p1({})\".format(p1.name))\n",
    "                    p1_score += 1\n",
    "                elif reward == -1:\n",
    "                    print(\"winner is p1({})\".format(p2.name))\n",
    "                    p2_score += 1\n",
    "                else:\n",
    "                    print(\"draw\")\n",
    "                    draw_score += 1\n",
    "                break\n",
    "        print(\"final result\")\n",
    "        env.print_board()\n",
    "        \n",
    "        # 최종 결과 출력\n",
    "        print(\"final result\")\n",
    "        env.print_board()\n",
    "        \n",
    "        # 한 게임 더?\n",
    "        answer = input(\"More Game? (y/n)\")\n",
    "        if(answer == \"n\"):\n",
    "            break\n",
    "print(\"p1({}) = {} p2({}) = {} draw = {}\".format(p1.name, p1_score, p2.name, p2_score,draw_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
